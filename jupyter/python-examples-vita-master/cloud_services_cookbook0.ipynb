{
 "metadata": {
  "name": "",
  "signature": "sha256:d28b929f6720ce1baa58335c36a0139469e8f0d4eab289d7613f4d4e0b531afc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Cloud Services Cookbook\n",
      "\n",
      "This notebook will review how to connect to and make use of cloud service providers.\n",
      "\n",
      "* Amazon S3\n",
      "* Dropbox\n",
      "* Twitter"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Amazon Web Services (AWS)\n",
      "\n",
      "AWS is Amazon's cloud framework. [boto](http://aws.amazon.com/es/sdk-for-python/) is the AWS SDK for Python.  boto provides Python APIs for many AWS services including Amazon S3, Amazon EC2, Amazon DynamoDB, and more. It supports Python 2 and 3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_help>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Setup\n",
      "Install the [boto](http://aws.amazon.com/es/sdk-for-python/) Python SDK library, which wraps the Amazon REST APIs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_setup>\n",
      "!pip install boto"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_setup>\n",
      "!pip install filechunkio"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Amazon S3\n",
      "Amazon Simple Storage Service (S3) provides file storage in the cloud.  Files are encapsulated as objects.  Amazon S3 enables developers to store, retrieve, delete, and set permissions and metadata on files through the object interfaces.\n",
      "\n",
      "To be able to perform operations on Amazon S3, you must first have an AWS account with S3 enabled.  You must also provide your AWS credentials in order to connect.  You can obtain your credentials by following these steps: \n",
      "\n",
      "1. Login to [AWS](https://portal.aws.amazon.com/billing/signup).\n",
      "2. Click `Account`.\n",
      "3. Click the `Security Credentials` link.\n",
      "4. Extract the key ID and secret access key. (You will use them in the code cells below to access and connect to Amazon S3).\n",
      "5. Grant Access to read/write on buckets and its contents.  \n",
      "    * Go to [AWS->IAM Management Console](https://console.aws.amazon.com/iam/)\n",
      "    * Click `Dashboard` > `Users` and select the user. \n",
      "    * Click on `User Policies` and add `PowerUserAccess` and `AdministratorAccess`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_s3_help>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Create Bucket\n",
      "Create a [bucket](http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html), the container used in Amazon S3 for data storage, and put an object in that bucket."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_s3_create_bucket>\n",
      "import boto\n",
      "import time\n",
      "\n",
      "aws_access_key_id = \"ACCESS KEY ID\"\n",
      "aws_secret_access_key = \"SECRET ACCESS KEY\"\n",
      "s3 = boto.connect_s3(aws_access_key_id, aws_secret_access_key)\n",
      "\n",
      "# Create a new bucket. Buckets must have a globally unique name (not just\n",
      "# unique to the account, so choose a good name).\n",
      "bucket = s3.create_bucket('aws_access_key_id')\n",
      "# Create a new key/value pair.\n",
      "key = bucket.new_key('mykey')\n",
      "key.set_contents_from_string(\"Hello World!\")\n",
      "# Sleep to ensure the data is eventually there.\n",
      "time.sleep(2)\n",
      "# Retrieve the contents of the key.\n",
      "print key.get_contents_as_string()\n",
      "# Delete key.\n",
      "key.delete()\n",
      "# Delete bucket.\n",
      "bucket.delete()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Store Data with Keys  \n",
      "Any type of data file can be stored in Amazon S3.  Each file is stored as a key/value pair, where the key is unique within a bucket.  \n",
      "\n",
      "The `Key` object is used in `boto` to keep track of data stored in Amazon S3.  Store new data in Amazon S3 by creating a new `Key` object and adding a value:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_s3_get_key>\n",
      "import boto\n",
      "from boto.s3.key import Key\n",
      "import time \n",
      "\n",
      "aws_access_key_id = \"ACCESS KEY ID\"\n",
      "aws_secret_access_key = \"SECRET ACCESS KEY\"\n",
      "s3 = boto.connect_s3(aws_access_key_id, aws_secret_access_key)\n",
      "b = s3.create_bucket('aws_access_key_id')\n",
      "k = b.new_key('newS3key')\n",
      "k.set_contents_from_string('This is a test of S3')\n",
      "# Sleep to ensure the data is eventually there.\n",
      "time.sleep(2)\n",
      "# Retrieve contents of key.\n",
      "print k.get_contents_as_string()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Upload/Download file to/from Amazon S3\n",
      "With a key, you can upload and download files to and from Amazon S3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_s3_key_contents_from_filename>\n",
      "import boto\n",
      "from boto.s3.key import Key\n",
      "\n",
      "aws_access_key_id = \"ACCESS KEY ID\"\n",
      "aws_secret_access_key = \"SECRET ACCESS KEY\"\n",
      "s3 = boto.connect_s3(aws_access_key_id, aws_secret_access_key)\n",
      "b = s3.create_bucket('aws_access_key_id')\n",
      "k = Key(b)\n",
      "k.key = 'my test file'\n",
      "testfile = \"draft.txt\"\n",
      "k.set_contents_from_filename(testfile)\n",
      "print('uploaded sucessfully')\n",
      "#download as:\n",
      "k.get_contents_to_filename('final-draft.txt')\n",
      "print('downloaded sucessfully')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Keys are validated to see if they exist. This can be disabled with `validate=False`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_s3_validate_key_false>\n",
      "import boto\n",
      "\n",
      "aws_access_key_id = \"ACCESS KEY ID\"\n",
      "aws_secret_access_key = \"SECRET ACCESS KEY\"\n",
      "s3 = boto.connect_s3(aws_access_key_id, aws_secret_access_key)\n",
      "b = s3.get_bucket('aws_access_key_id') # substitute your bucket name here\n",
      "# Will hit the API to check if it exists.\n",
      "possible_key = b.get_key('newS3key') # substitute your key name here\n",
      "print(possible_key)\n",
      "print('\\n')\n",
      "# Won't hit the API.\n",
      "key_we_know_is_there = b.get_key('newS3key', validate=False)\n",
      "print(key_we_know_is_there)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Upload Large Data  \n",
      "Amazon S3 supports splitting large files into smaller chunks.  Each chunk is uploaded and then Amazon S3 combines them into a single file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_s3_upload_filechunkio>\n",
      "import math, os\n",
      "import boto\n",
      "from filechunkio import FileChunkIO\n",
      "\n",
      "aws_access_key_id = \"ACCESS KEY ID\"\n",
      "aws_secret_access_key = \"SECRET ACCESS KEY\"\n",
      "s3 = boto.connect_s3(aws_access_key_id, aws_secret_access_key)\n",
      "b = s3.get_bucket('aws_access_key_id')\n",
      "# Get file info\n",
      "source_path = 'big.txt'\n",
      "source_size = os.stat(source_path).st_size\n",
      "# Create a multipart upload request\n",
      "mp = b.initiate_multipart_upload(os.path.basename(source_path))\n",
      "# Use a chunk size of 50 MiB (feel free to change this)\n",
      "chunk_size = 52428800\n",
      "chunk_count = int(math.ceil(source_size / chunk_size))\n",
      "# Send the file parts, using FileChunkIO to create a file-like object\n",
      "# that points to a certain byte range within the original file. \n",
      "# S3 set bytes to never exceed the original file size.\n",
      "for i in range(chunk_count + 1):\n",
      "    offset = chunk_size * i\n",
      "    bytes = min(chunk_size, source_size - offset)\n",
      "    with FileChunkIO(source_path, 'r', offset=offset,\n",
      "                     bytes=bytes) as fp:\n",
      "        mp.upload_part_from_file(fp, part_num=i + 1)\n",
      "# Finish the upload\n",
      "mp.complete_upload()\n",
      "print('Upload Complete')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Get Bucket\n",
      "Get a bucket."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_s3_get_bucket>\n",
      "import boto\n",
      "\n",
      "aws_access_key_id = \"ACCESS KEY ID\"\n",
      "aws_secret_access_key = \"SECRET ACCESS KEY\"\n",
      "s3 = boto.connect_s3(aws_access_key_id, aws_secret_access_key)\n",
      "mybucket = s3.get_bucket('mybucket') # Substitute in your bucket name, might need an entire path \n",
      "mybucket.list()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Delete Bucket  \n",
      "Delete a bucket.  \n",
      "\n",
      "**Note**: you must first delete the contents of the bucket, or an error is raised."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_s3_delete_bucket>\n",
      "import boto\n",
      "\n",
      "aws_access_key_id = \"ACCESS KEY ID\"\n",
      "aws_secret_access_key = \"SECRET ACCESS KEY\"\n",
      "s3 = boto.connect_s3(aws_access_key_id, aws_secret_access_key)\n",
      "full_bucket = s3.get_bucket('replace')\n",
      "# It's full of keys. Delete them all.\n",
      "for key in full_bucket.list():\n",
      "    key.delete()\n",
      "# The bucket is empty now. Delete it.\n",
      "s3.delete_bucket('replace')\n",
      "print('Deleted')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### List All Buckets  \n",
      "Retrieve all created buckets. This returns a `ResultSet` object. The `ResultSet` can be used as a `sequence` or `list` type object to retrieve `Bucket` objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_s3_list_bucket>\n",
      "import boto\n",
      "\n",
      "aws_access_key_id = \"ACCESS KEY ID\"\n",
      "aws_secret_access_key = \"SECRET ACCESS KEY\"\n",
      "s3 = boto.connect_s3(aws_access_key_id, aws_secret_access_key)\n",
      "#get\n",
      "rs = s3.get_all_buckets()\n",
      "#list them out\n",
      "len(rs)\n",
      "for b in rs:\n",
      "    print b.name\n",
      "#<listing of available buckets>\n",
      "#show an individual one\n",
      "b = rs[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Access Control   \n",
      "The Access Control List (ACL) allows the ability to set permissions on read/write operations on objects.\n",
      "There are two ways to set the `ACL` for an object:\n",
      "\n",
      "1. Create a custom ACL that grants specific rights to specific users. At the moment, the users that are specified within grants have to be registered users of Amazon Web Services so this isn\u2019t as useful or as general as it could be.\n",
      "2. Use a \u201ccanned\u201d access control policy. There are four canned policies defined:\n",
      "    * `private`: Owner gets `FULL_CONTROL`. No one else has any access rights.\n",
      "    * `public-read`: Owners gets `FULL_CONTROL` and the anonymous principal is granted `READ` access.\n",
      "    * `public-read-write`: Owner gets `FULL_CONTROL` and the anonymous principal is granted `READ` and `WRITE` access.\n",
      "    * `authenticated-read`: Owner gets `FULL_CONTROL` and any principal authenticated as a registered Amazon S3 user is granted `READ` access.\n",
      "\n",
      "Set the bucket to `public-read` and the ACL for a key object the bucket as an argument."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:amazon_s3_get_acl>\n",
      "import boto\n",
      "\n",
      "aws_access_key_id = \"ACCESS KEY ID\"\n",
      "aws_secret_access_key = \"SECRET ACCESS KEY\"\n",
      "s3 = boto.connect_s3(aws_access_key_id, aws_secret_access_key)\n",
      "b = s3.get_bucket('aws_access_key_id3') #previously created bucket\n",
      "k = b.get_key('newS3key') #previously created key\n",
      "#set acl\n",
      "b.set_acl('public-read', 'newS3key')\n",
      "# set acl bucket with key\n",
      "k.set_acl('public-read')\n",
      "#get acl \n",
      "acp = b.get_acl()\n",
      "#display perms\n",
      "for grant in acp.acl.grants:\n",
      "    print grant.permission, grant.display_name, grant.email_address, grant.id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Dropbox\n",
      "\n",
      "Dropbox offers two main APIs:\n",
      "\n",
      "The [Core API](https://www.dropbox.com/developers/core) allows read and write access on Dropbox, such as downloading /uploading files, and modifying/deleting items. \n",
      "\n",
      "The [DataStore API](https://www.dropbox.com/developers/datastore) is focused more on applications that connect to Dropbox to sync data such as calendars, structured data like lists etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:dropbox_help>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Setup\n",
      "\n",
      "Install the [dropbox](https://github.com/tweepy/tweepy) Python client library, which wraps the Dropbox REST APIs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:dropbox_setup>\n",
      "!pip install dropbox"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Authentication\n",
      "\n",
      "Dropbox uses Oauth to authenticate users.  To access Dropbox from a notebook, you must first register the notebook as an application to be able to authenticate.\n",
      "\n",
      "1. Go to the [App Console](https://www.dropbox.com/developers/apps). \n",
      "2. Click on \"Create New App\"\n",
      "3. Choose \"Dropbox API App\", then choose the following options: \n",
      "    * Type of data: **Files and Datastores**\n",
      "    * App is limited to your own folder: **No**\n",
      "    * Type of files your app needs to access: **All**\n",
      "4. Select a name for your app (must be unique). \n",
      "5. Click \"Create App\".\n",
      "6. Note the app key and app secret. You will need these to authorize access.  (Don't share these with anyone). \n",
      "\n",
      "The Dropbox client has a class called [DropboxOAuth2FlowNoRedirect](https://www.dropbox.com/developers/core/docs/python#DropboxOAuth2FlowNoRedirect) that our notebook app can use instead of providing an HTTP callback url during the OAuth handshake.  This class presents the end user with an authorization url, from which the user can obtain an authorization code.  From the [Dropbox Documentation](https://www.dropbox.com/developers/core/start/python):\n",
      ">\"This URL can ask the user to authorize your app. The URL will be printed and will ask the user to press the `Enter` key to confirm that they've authorized the app. However, in real-world apps, it's reccommended to automatically send the user to the authorization URL and pass in a callback URL so that the user is seamlessly redirected back to the app after pressing a button.\"\n",
      "\n",
      "After providing the authorization code to the Dropbox client, the notebook can use the client to access the user's account and perform actions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_auth>\n",
      "import dropbox\n",
      "\n",
      "# Get your app key and secret from the Dropbox developer website\n",
      "app_key = 'app_key'\n",
      "app_secret = 'app_secret'\n",
      "# oauth dance\n",
      "flow = dropbox.client.DropboxOAuth2FlowNoRedirect(app_key, app_secret)\n",
      "authorize_url = flow.start()\n",
      "print '1. Go to: ' + authorize_url\n",
      "print '2. Click \"Allow\" (you may have to log in first)'\n",
      "print '3. Copy the authorization code.'\n",
      "# click on the link, opens new window, get the code, \n",
      "# paste the code in the cell as plaintext, has a timer so be quick!\n",
      "code = raw_input(\"Enter the authorization code here: \").strip()\n",
      "# This will fail if the user enters an invalid authorization code\n",
      "access_token, user_id = flow.finish(code)\n",
      "#test access to core api\n",
      "client = dropbox.client.DropboxClient(access_token)\n",
      "print 'linked account: ', client.account_info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Dropbox Core API\n",
      "\n",
      "The Core API allows not just uploading and downloading files but other options such as search, revisions, and restoring files. \n",
      "The APi has a functionality to get a printed dictionary with the results of its commands. If the command fails, the API will return an error with the details."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_core_help>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Upload File  \n",
      "\n",
      "`put_file()` takes a path pointing to where the file should be uploaded to Dropbox, and then a file-like object or string to be uploaded there.  \n",
      "\n",
      "**Create on your local machine a draft.txt.**  \n",
      "This command will upload it as magnum-opus.txt (change to what name you wish).\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_core_put_file>\n",
      "import dropbox\n",
      "\n",
      "f = open('draft.txt', 'rb')\n",
      "response = client.put_file('/magnum-opus.txt', f)\n",
      "#print response with details\n",
      "print \"Uploaded:\", response"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Create Folder  \n",
      "\n",
      "`file_create_folder(path)`  \n",
      "Select the path of the folder to be created. \n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_core_create_folder>\n",
      "import dropbox\n",
      "\n",
      "response = client.file_create_folder('/mypythonapp')\n",
      "print \"uploaded:\", response"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Copy or Move File  \n",
      "\n",
      "Copy a file with `file_copy('from_path', 'to_path')`\n",
      "\n",
      "To move, use `file_move('from_path', 'to_path')`\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_core_file_copy>\n",
      "import dropbox\n",
      "\n",
      "response = client.file_copy('/magnum-opus.txt','/Dropbox/mypythonapp/')\n",
      "print \"copied:\", response"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Folder metadata  \n",
      "\n",
      "Get the info of an entire folder by using the `metadata()` call\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_core_metadata>\n",
      "import dropbox\n",
      "\n",
      "folder_metadata = client.metadata('/')\n",
      "print \"metadata:\", folder_metadata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Download File  \n",
      "\n",
      "The `get_file_and_metadata` method downloads the file and its metadata.  \n",
      "The method also returns the metadata at its current revision. Every time a change is made to the file, the `rev` field of the file's metadata changes as well.  \n",
      "By saving the revision when the file is downloaded, it will be easy to tell if it's been modified by another device and whether to choose to download the newer revision.\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_core_get_file_and_metadata>\n",
      "import dropbox\n",
      "\n",
      "f, metadata = client.get_file_and_metadata('/magnum-opus.txt')\n",
      "out = open('magnum-opus.txt', 'wb')\n",
      "out.write(f.read())\n",
      "out.close()\n",
      "print metadata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Search files  \n",
      "\n",
      "`search(path, query, file_limit=1000, include_deleted=False)`  \n",
      "\n",
      "In which  \n",
      "* `path`: folder to search  \n",
      "* `query`: minimum 3 characters, what to look for, case sensitive.  \n",
      "* `file_limit`: up to 1000 files to display  \n",
      "* `include_deleted`: whether to include deleted files in the search results  \n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_core_search>\n",
      "import dropbox\n",
      "\n",
      "response = client.search('/','magnum', file_limit=100, include_deleted= False)\n",
      "print \"Results:\", response"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Share File/Folder  \n",
      "\n",
      "`share(path, short_url=True)`\n",
      "\n",
      "Create a shareable link to a file or folder.\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_core_share>\n",
      "import dropbox\n",
      "\n",
      "response = client.share('/magnum-opus.txt',short_url=True)\n",
      "print \"Results:\", response"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Upload Large Files\n",
      "\n",
      "Upload large files with the `ChunkedUploader` object. It will break up the file into chunks and upload it in bits. \n",
      "\n",
      "`get_chunked_uploader(file_obj, length)`  \n",
      "* `file_obj` is the file to be uploaded  \n",
      "* `length`, number of bytes to upload  \n",
      "\n",
      "Use a `try/catch` block to upload; the SDK leaves the error handling and retry logic to the developer to implement.\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> \n",
      "\n",
      "**Create a text file called big.txt**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:dropbox_core_chunked_uploader>\n",
      "import dropbox\n",
      "\n",
      "bigFile = open(\"big.txt\", 'rb')\n",
      "size= 1024\n",
      "\n",
      "uploader = client.get_chunked_uploader(bigFile, size)\n",
      "print \"uploading: \", size\n",
      "while uploader.offset < size:\n",
      "    try:\n",
      "        upload = uploader.upload_chunked()\n",
      "        print('finished1')\n",
      "    except rest.ErrorResponse, e:\n",
      "            # implement error handling and retry logic here\n",
      "        print('Error trying to upload')\n",
      "uploader.finish('/bigFile.txt')\n",
      "print('Uploaded')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Delete file  \n",
      "\n",
      "Delete a file or folder with `file_delete('path')`  \n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_core_file_delete>\n",
      "import dropbox\n",
      "#delete\n",
      "response = client.file_delete('/magnum-opus.txt')\n",
      "print \"Results:\", response"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Datastore API\n",
      "The Datasotre API supports multiple platforms, offline access, and automatic conflict resolution.\n",
      "\n",
      "**Client and datastore manager**  \n",
      "\n",
      "The client lets the app start the authentication process to link with a user's Dropbox account. Once it's linked to an account (`dropbox_setup` code), the client can create a datastore manager, which can open datastores, list datastores, etc.\n",
      "\n",
      "**Datastores and tables**  \n",
      "\n",
      "Datastores are containers for an app's data. Each datastore contains a set of tables, and each table is a collection of records. A table allows to query existing records or insert new ones.\n",
      "\n",
      "Any datastore with a shareable ID can be shared by assigning roles to principals, creating an access control list. Any Dropbox account with the correct permissions will then be able to open the shared datastore by ID.\n",
      "\n",
      "**Records**  \n",
      "\n",
      "Records are how an app stores data. Each record consists of a set of fields, each with a name and a value. Values can be simple objects, like strings, integers, and booleans, or they can be lists of simple objects. A record has an ID and can have any number of fields."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:dropbox_datastore_help>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Create datastore and table \n",
      "\n",
      "With an access token in hand, the next step is to open the default datastore. Each app has its own default datastore per user. \n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_datastore_get_table>\n",
      "import dropbox\n",
      "from dropbox.datastore import DatastoreError, DatastoreManager, Date, Bytes\n",
      "\n",
      "#define a datastore\n",
      "manager = DatastoreManager(client)\n",
      "datastore = manager.open_default_datastore()\n",
      "print(datastore)\n",
      "print('\\n')\n",
      "#create a table named 'tasks'\n",
      "tasks_table = datastore.get_table('tasks')\n",
      "print(tasks_table)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Upload Record  \n",
      "\n",
      "A record is a set of name and value pairs called fields. Records in the same table can have different combinations of fields; there's no schema on the table which contains them.\n",
      "\n",
      "The Python SDK provides a method called `transaction` that uploads data to the server keeping track of conflicts.\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_datastore_record_transaction>\n",
      "import dropbox\n",
      "from dropbox.datastore import DatastoreError, DatastoreManager, Date, Bytes\n",
      "\n",
      "#define a datastore\n",
      "manager = DatastoreManager(client)\n",
      "datastore = manager.open_default_datastore()\n",
      "print(datastore)\n",
      "print('\\n')\n",
      "#create a table named 'tasks'\n",
      "tasks_table = datastore.get_table('My tasks')\n",
      "print(tasks_table)\n",
      "#load record and commit to dropbox with transaction\n",
      "def do_insert():\n",
      "    tasks_table.insert(taskname='Buy milk', completed=False)\n",
      "datastore.transaction(do_insert, max_tries=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Access, Edit and Delete a record  \n",
      "\n",
      "Review uploaded datastores in the [Developer Website](https://www.dropbox.com/developers/apps/datastores)  \n",
      "\n",
      "`.get()`, `.set()`, `.delete()`   \n",
      "Access, Edit and Delete a DataStore\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_datastore_open_get_delete>\n",
      "import dropbox\n",
      "from dropbox.datastore import DatastoreError, DatastoreManager, Date, Bytes\n",
      "\n",
      "#define a datastore\n",
      "manager = DatastoreManager(client)\n",
      "datastore = manager.open_default_datastore()\n",
      "print(datastore)\n",
      "print('\\n')\n",
      "#access a datastore\n",
      "task_name = first_task.get('taskname')\n",
      "#edit a datastore\n",
      "def do_update():\n",
      "    first_task.set('completed', True)\n",
      "datastore.transaction(do_update, max_tries=4)\n",
      "#delete a datastore\n",
      "def do_delete():\n",
      "    first_task.delete()\n",
      "datastore.transaction(do_delete, max_tries=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Query Record  \n",
      "\n",
      "The query method takes a set of conditions that the fields of a record must match to be returned in the result set. All records must have a field with that name and that field's value must be exactly equal to the specified value, case sensitive too.\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_datastore_table_query>\n",
      "import dropbox\n",
      "from dropbox.datastore import DatastoreError, DatastoreManager, Date, Bytes\n",
      "\n",
      "#define a datastore\n",
      "manager = DatastoreManager(client)\n",
      "datastore = manager.open_default_datastore()\n",
      "print(datastore)\n",
      "print('\\n')\n",
      "tasks = tasks_table.query(completed=False)\n",
      "for task in tasks:\n",
      "    print task.get('taskname')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Share datastore  \n",
      "\n",
      "The Datastore API allows sharing a datastore across multiple Dropbox accounts.\n",
      "\n",
      "Any user who has the datastore ID and the appropriate permissions may then open the datastore.  \n",
      "View the access control list at any time for a datastore as a mapping of roles applied to principals using the `list_roles()` method. Find out the current user's role with the `get_effective_role()` method.\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `dropbox_auth` step first to authorize with Dropbox. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: dropbox_datastore_share_set_role>\n",
      "import dropbox\n",
      "from dropbox.datastore import DatastoreError, DatastoreManager, Date, Bytes\n",
      "\n",
      "# Shareable datastore\n",
      "datastore = manager.create_datastore()\n",
      "#set a role, more info in the API docs\n",
      "datastore.set_role(Datastore.PUBLIC, Datastore.EDITOR)\n",
      "print(datastore)\n",
      "print('\\n \\n')\n",
      "#paste data store id below!\n",
      "datastore_id = \n",
      "datastore1 = manager.open_datastore(datastore_id)\n",
      "print(datastore1)\n",
      "print('\\n \\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Review the Datastore Python API docs [here](https://www.dropbox.com/developers/datastore/docs/python)**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Twitter\n",
      "Twitter offers [REST APIs](https://dev.twitter.com/rest/public) and [Streaming APIs](https://dev.twitter.com/streaming/overview) to connect and download tweets.  The documentation can be found [here](https://dev.twitter.com/overview/documentation).\n",
      "\n",
      "The Python community has created wrappers around the Twitter API:  \n",
      "\n",
      "* [python-twitter](https://github.com/bear/python-twitter) (Apache 2.0 License)  \n",
      "* [tweepy](https://github.com/tweepy/tweepy)  (MIT License)  \n",
      "\n",
      "We will use **tweepy** in this notebook, which wraps the [Twitter REST API](https://dev.twitter.com/rest/public).  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help:twitter_help>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Setup\n",
      "Install the [tweepy](https://github.com/tweepy/tweepy) Python client library, which wraps the Twitter REST APIs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: twitter_setup>\n",
      "!pip install tweepy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Authorize\n",
      "The Twitter API uses OAuth for authentication. To allow an application to access Twitter, you must register the app on Twitter's web site.  You also need to obtain app keys and app secrets to authenticate.   \n",
      "\n",
      "1. Go to https://apps.twitter.com/ (Sign in or create an account) \n",
      "1. Create New App. Provide the necessary information.\n",
      "1. Select the application and click on \"API Keys and access tokens\" tab\n",
      "1. Copy and paste the following into the code cell below:\n",
      "    * access token/secret: Used to make API requests on your account's behalf.\n",
      "    * consumer key, consumer secret: Allows the app to read and write user data.\n",
      "    \n",
      "First, we need to authorize to Twitter.  We only need to do this once per session."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: twitter_auth>\n",
      "import tweepy\n",
      "from tweepy import OAuthHandler\n",
      "\n",
      "#replace with your data!\n",
      "consumer_key = 'key'\n",
      "consumer_secret = 'secret'\n",
      "access_token = 'token'\n",
      "access_token_secret = 'token_secret'\n",
      "#oauth dance\n",
      "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "# Authorize via Twitter authorization url\n",
      "# And since we aren't using a web callback url, \n",
      "# We have to enter the auth code manually\n",
      "redirect_url = auth.get_authorization_url()\n",
      "print(redirect_url)\n",
      "verifier = raw_input(\"Enter the authorization code here: \").strip()\n",
      "# Get access token and save it\n",
      "try:\n",
      "    auth.get_access_token(verifier)\n",
      "except tweepy.TweepError:\n",
      "    print 'Error! Failed to get access token.'\n",
      "auth.set_access_token(access_token, access_token_secret)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Get Tweets\n",
      "Use Twitter API retrieve tweets from our own (home) timeline.\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `twitter_auth` step first to authorize with Twitter. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: twitter_tweets>\n",
      "\n",
      "# Construct the API instance\n",
      "api = tweepy.API(auth)\n",
      "# Get tweets\n",
      "public_tweets = api.home_timeline()\n",
      "for tweet in public_tweets:\n",
      "    print tweet.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Search Tweets  \n",
      "\n",
      "Search the text of tweets.\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `twitter_auth` step first to authorize with Twitter. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: twitter_search>\n",
      "import tweepy\n",
      "\n",
      "# Construct the API instance\n",
      "api = tweepy.API(auth)\n",
      "#search and iterate\n",
      "public_tweets = api.search('the interview')\n",
      "for tweet in public_tweets:\n",
      "    print tweet.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###List Followers \n",
      "\n",
      "Paginate through a user's followers.\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `twitter_auth` step first to authorize with Twitter. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: twitter_lookup_users>\n",
      "import tweepy\n",
      "import itertools\n",
      "\n",
      "# Construct the API instance\n",
      "api = tweepy.API(auth)\n",
      "#replace 'user' string with a valid Twitter handle\n",
      "followers = api.followers_ids('user')\n",
      "\n",
      "def paginate(iterable, page_size):\n",
      "    while True:\n",
      "        i1, i2 = itertools.tee(iterable)\n",
      "        iterable, page = (itertools.islice(i1, page_size, None),\n",
      "                list(itertools.islice(i2, page_size)))\n",
      "        if len(page) == 0:\n",
      "            break\n",
      "        yield page\n",
      "for page in paginate(followers, 100):\n",
      "    results = api.lookup_users(user_ids=page)\n",
      "    for result in results:\n",
      "        print result.screen_name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Trending Topics\n",
      "\n",
      "Returns the top **ten** topics that are currently trending on Twitter. The response includes the time of the request, the name of each trend, and the url to the Twitter Search results page for that topic. This recipe will strip and only print the hashtags with the # symbol.\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `twitter_auth` step first to authorize with Twitter. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: twitter_trends_place>\n",
      "import tweepy\n",
      "\n",
      "# Construct the API instance\n",
      "api = tweepy.API(auth)\n",
      "# trending topics are limited to geographical location\n",
      "# use the geo code from https://developer.yahoo.com/geo/geoplanet/\n",
      "trending = api.trends_place(1)\n",
      "# trending is a list with only one element in it, which is a \n",
      "# dict which we'll put in data.\n",
      "data = trending[0] \n",
      "# grab the trends\n",
      "trends = data['trends']\n",
      "# grab the name from each trend; place in a list\n",
      "names = [trend['name'] for trend in trends]\n",
      "# put all the names together with a ', ' separating them\n",
      "trendsName = ', '.join(names)\n",
      "print(trendsName)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Cursor  \n",
      "\n",
      "Tweepy has the `Cursor` object to iterate through timelines, user lists, direct messages, etc.\n",
      "The `cursor` object returns a deserialized `json` object. \n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `twitter_auth` step first to authorize with Twitter. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: twitter_cursor>\n",
      "import tweepy\n",
      "\n",
      "api = tweepy.API(auth)\n",
      "tweepy.Cursor(api.user_timeline, id=\"twitter\")\n",
      "for page in tweepy.Cursor(api.user_timeline).pages():\n",
      "    # page is a list of tweets, with replies\n",
      "    print(page)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###List All\n",
      "Get all lists that a user is subscribed to.\n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `twitter_auth` step first to authorize with Twitter. </div> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: twitter_list_all>\n",
      "import tweepy\n",
      "\n",
      "api = tweepy.API(auth)\n",
      "for status in api.lists_all(id = 'user_auth'):\n",
      "    print pprint(status)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Stream API\n",
      "\n",
      "The streaming APIs allow to pull real-time data from Twitter. \n",
      "\n",
      "Twitter offers several streaming parameters, each customized to certain use cases.\n",
      "\n",
      "* _Public streams_-\tStreams of the public data in Twitter. Example: hashtags\n",
      "* _User streams_-\tSingle-user streams. Example: tweets from a specific user.\n",
      "* _Site streams_-\tThe multi-user version of user streams. \n",
      "\n",
      "The streaming process gets the Tweets and performs any organization needed before storing the result into a data store. \n",
      "\n",
      "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** You must run `twitter_auth` step first to authorize with Twitter. </div> \n",
      "\n",
      "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">**Warning** This will run indefinitely until you stop the cell. </div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<help: twitter_stream>\n",
      "import tweepy\n",
      "from tweepy.streaming import StreamListener\n",
      "from tweepy import Stream\n",
      "import json\n",
      "\n",
      "\n",
      "# This is the listener, resposible for receiving data\n",
      "class StdOutListener(tweepy.StreamListener):\n",
      "    def on_data(self, data):\n",
      "        # Twitter returns data in JSON format - we need to decode it first\n",
      "        decoded = json.loads(data)\n",
      "        # Also, we convert UTF-8 to ASCII ignoring all bad characters sent by users\n",
      "        print '@%s: %s' % (decoded['user']['screen_name'], decoded['text'].encode('ascii', 'ignore'))\n",
      "        print ''\n",
      "        return True\n",
      "    def on_error(self, status):\n",
      "        print status\n",
      "        \n",
      "print \"Showing all new tweets for #python:\"\n",
      "stream = tweepy.Stream(auth, StdOutListener())\n",
      "stream.filter(track=['python'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}